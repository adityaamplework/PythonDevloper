{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OHE implementaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "# # Define sample text data and labels\n",
    "# text_samples = [\n",
    "#     \"I love this product! It's amazing.\",\n",
    "#     \"Terrible experience, I hate it.\",\n",
    "#     \"This is the best purchase I've made.\",\n",
    "#     \"Worst service ever. Do not recommend!\",\n",
    "#     \"I am very happy with my order.\",\n",
    "#     \"So disappointing, not what I expected.\",\n",
    "#     \"Absolutely fantastic! Great quality.\",\n",
    "#     \"Poor quality, broke in a week.\",\n",
    "#     \"Customer support was very helpful.\",\n",
    "#     \"I will never buy from here again!\"\n",
    "# ]\n",
    "\n",
    "# # Generate a random dataset\n",
    "# random.seed(42)\n",
    "# dataset_size = 100  # Change this for larger datasets\n",
    "\n",
    "# data = {\n",
    "#     \"text\": [random.choice(text_samples) for _ in range(dataset_size)],\n",
    "#     \"label\": [random.choice([0, 1]) for _ in range(dataset_size)]  # 0 = Negative, 1 = Positive\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Save to CSV\n",
    "# csv_filename = \"random_nlp_dataset.csv\"\n",
    "# df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# print(f\"Dataset saved as {csv_filename}\")\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /usr/local/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download('punkt', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"random_nlp_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Terrible experience, I hate it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this product! It's amazing.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am very happy with my order.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worst service ever. Do not recommend!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worst service ever. Do not recommend!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  label\n",
       "0        Terrible experience, I hate it.      0\n",
       "1     I love this product! It's amazing.      1\n",
       "2         I am very happy with my order.      1\n",
       "3  Worst service ever. Do not recommend!      1\n",
       "4  Worst service ever. Do not recommend!      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop word Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word,pos='v') for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned=df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    absolutely  amaze  best  break  buy  customer  disappoint  ever  expect  \\\n",
      "0            0      0     0      0    0         0           0     0       0   \n",
      "1            0      1     0      0    0         0           0     0       0   \n",
      "2            0      0     0      0    0         0           0     0       0   \n",
      "3            0      0     0      0    0         0           0     1       0   \n",
      "4            0      0     0      0    0         0           0     1       0   \n",
      "..         ...    ...   ...    ...  ...       ...         ...   ...     ...   \n",
      "95           1      0     0      0    0         0           0     0       0   \n",
      "96           0      0     0      1    0         0           0     0       0   \n",
      "97           0      0     1      0    0         0           0     0       0   \n",
      "98           0      0     0      0    0         0           0     0       0   \n",
      "99           0      0     1      0    0         0           0     0       0   \n",
      "\n",
      "    experience  ...  poor  product  purchase  quality  recommend  service  \\\n",
      "0            1  ...     0        0         0        0          0        0   \n",
      "1            0  ...     0        1         0        0          0        0   \n",
      "2            0  ...     0        0         0        0          0        0   \n",
      "3            0  ...     0        0         0        0          1        1   \n",
      "4            0  ...     0        0         0        0          1        1   \n",
      "..         ...  ...   ...      ...       ...      ...        ...      ...   \n",
      "95           0  ...     0        0         0        1          0        0   \n",
      "96           0  ...     1        0         0        1          0        0   \n",
      "97           0  ...     0        0         1        0          0        0   \n",
      "98           0  ...     0        0         0        0          0        0   \n",
      "99           0  ...     0        0         1        0          0        0   \n",
      "\n",
      "    support  terrible  week  worst  \n",
      "0         0         1     0      0  \n",
      "1         0         0     0      0  \n",
      "2         0         0     0      0  \n",
      "3         0         0     0      1  \n",
      "4         0         0     0      1  \n",
      "..      ...       ...   ...    ...  \n",
      "95        0         0     0      0  \n",
      "96        0         0     1      0  \n",
      "97        0         0     0      0  \n",
      "98        0         0     0      0  \n",
      "99        0         0     0      0  \n",
      "\n",
      "[100 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Bag of Word\n",
    "vectorizer = CountVectorizer()\n",
    "bow_features = vectorizer.fit_transform(data_cleaned)\n",
    "\n",
    "# Convert to DataFrame\n",
    "bow_df = pd.DataFrame(bow_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(bow_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    absolutely    amaze  best     break  buy  customer  disappoint  ever  \\\n",
      "0      0.00000  0.00000   0.0  0.000000  0.0       0.0         0.0   0.0   \n",
      "1      0.00000  0.57735   0.0  0.000000  0.0       0.0         0.0   0.0   \n",
      "2      0.00000  0.00000   0.0  0.000000  0.0       0.0         0.0   0.0   \n",
      "3      0.00000  0.00000   0.0  0.000000  0.0       0.0         0.0   0.5   \n",
      "4      0.00000  0.00000   0.0  0.000000  0.0       0.0         0.0   0.5   \n",
      "..         ...      ...   ...       ...  ...       ...         ...   ...   \n",
      "95     0.51734  0.00000   0.0  0.000000  0.0       0.0         0.0   0.0   \n",
      "96     0.00000  0.00000   0.0  0.527035  0.0       0.0         0.0   0.0   \n",
      "97     0.00000  0.00000   0.5  0.000000  0.0       0.0         0.0   0.0   \n",
      "98     0.00000  0.00000   0.0  0.000000  0.0       0.0         0.0   0.0   \n",
      "99     0.00000  0.00000   0.5  0.000000  0.0       0.0         0.0   0.0   \n",
      "\n",
      "    expect  experience  ...      poor  product  purchase   quality  recommend  \\\n",
      "0      0.0     0.57735  ...  0.000000  0.00000       0.0  0.000000        0.0   \n",
      "1      0.0     0.00000  ...  0.000000  0.57735       0.0  0.000000        0.0   \n",
      "2      0.0     0.00000  ...  0.000000  0.00000       0.0  0.000000        0.0   \n",
      "3      0.0     0.00000  ...  0.000000  0.00000       0.0  0.000000        0.5   \n",
      "4      0.0     0.00000  ...  0.000000  0.00000       0.0  0.000000        0.5   \n",
      "..     ...         ...  ...       ...      ...       ...       ...        ...   \n",
      "95     0.0     0.00000  ...  0.000000  0.00000       0.0  0.443936        0.0   \n",
      "96     0.0     0.00000  ...  0.527035  0.00000       0.0  0.408293        0.0   \n",
      "97     0.0     0.00000  ...  0.000000  0.00000       0.5  0.000000        0.0   \n",
      "98     0.0     0.00000  ...  0.000000  0.00000       0.0  0.000000        0.0   \n",
      "99     0.0     0.00000  ...  0.000000  0.00000       0.5  0.000000        0.0   \n",
      "\n",
      "    service  support  terrible      week  worst  \n",
      "0       0.0      0.0   0.57735  0.000000    0.0  \n",
      "1       0.0      0.0   0.00000  0.000000    0.0  \n",
      "2       0.0      0.0   0.00000  0.000000    0.0  \n",
      "3       0.5      0.0   0.00000  0.000000    0.5  \n",
      "4       0.5      0.0   0.00000  0.000000    0.5  \n",
      "..      ...      ...       ...       ...    ...  \n",
      "95      0.0      0.0   0.00000  0.000000    0.0  \n",
      "96      0.0      0.0   0.00000  0.527035    0.0  \n",
      "97      0.0      0.0   0.00000  0.000000    0.0  \n",
      "98      0.0      0.0   0.00000  0.000000    0.0  \n",
      "99      0.0      0.0   0.00000  0.000000    0.0  \n",
      "\n",
      "[100 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data_cleaned)\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    absolutely fantastic  absolutely fantastic great  best purchase  \\\n",
      "0                      0                           0              0   \n",
      "1                      0                           0              0   \n",
      "2                      0                           0              0   \n",
      "3                      0                           0              0   \n",
      "4                      0                           0              0   \n",
      "..                   ...                         ...            ...   \n",
      "95                     1                           1              0   \n",
      "96                     0                           0              0   \n",
      "97                     0                           0              1   \n",
      "98                     0                           0              0   \n",
      "99                     0                           0              1   \n",
      "\n",
      "    best purchase ive  break week  customer support  customer support helpful  \\\n",
      "0                   0           0                 0                         0   \n",
      "1                   0           0                 0                         0   \n",
      "2                   0           0                 0                         0   \n",
      "3                   0           0                 0                         0   \n",
      "4                   0           0                 0                         0   \n",
      "..                ...         ...               ...                       ...   \n",
      "95                  0           0                 0                         0   \n",
      "96                  0           1                 0                         0   \n",
      "97                  1           0                 0                         0   \n",
      "98                  0           0                 0                         0   \n",
      "99                  1           0                 0                         0   \n",
      "\n",
      "    disappoint expect  ever recommend  experience hate  ...  \\\n",
      "0                   0               0                1  ...   \n",
      "1                   0               0                0  ...   \n",
      "2                   0               0                0  ...   \n",
      "3                   0               1                0  ...   \n",
      "4                   0               1                0  ...   \n",
      "..                ...             ...              ...  ...   \n",
      "95                  0               0                0  ...   \n",
      "96                  0               0                0  ...   \n",
      "97                  0               0                0  ...   \n",
      "98                  0               0                0  ...   \n",
      "99                  0               0                0  ...   \n",
      "\n",
      "    purchase ive make  quality break  quality break week  service ever  \\\n",
      "0                   0              0                   0             0   \n",
      "1                   0              0                   0             0   \n",
      "2                   0              0                   0             0   \n",
      "3                   0              0                   0             1   \n",
      "4                   0              0                   0             1   \n",
      "..                ...            ...                 ...           ...   \n",
      "95                  0              0                   0             0   \n",
      "96                  0              1                   1             0   \n",
      "97                  1              0                   0             0   \n",
      "98                  0              0                   0             0   \n",
      "99                  1              0                   0             0   \n",
      "\n",
      "    service ever recommend  support helpful  terrible experience  \\\n",
      "0                        0                0                    1   \n",
      "1                        0                0                    0   \n",
      "2                        0                0                    0   \n",
      "3                        1                0                    0   \n",
      "4                        1                0                    0   \n",
      "..                     ...              ...                  ...   \n",
      "95                       0                0                    0   \n",
      "96                       0                0                    0   \n",
      "97                       0                0                    0   \n",
      "98                       0                0                    0   \n",
      "99                       0                0                    0   \n",
      "\n",
      "    terrible experience hate  worst service  worst service ever  \n",
      "0                          1              0                   0  \n",
      "1                          0              0                   0  \n",
      "2                          0              0                   0  \n",
      "3                          0              1                   1  \n",
      "4                          0              1                   1  \n",
      "..                       ...            ...                 ...  \n",
      "95                         0              0                   0  \n",
      "96                         0              0                   0  \n",
      "97                         0              0                   0  \n",
      "98                         0              0                   0  \n",
      "99                         0              0                   0  \n",
      "\n",
      "[100 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# N-grams\n",
    "vectorizer_ngram = CountVectorizer(ngram_range=(2, 3))\n",
    "ngram_features = vectorizer_ngram.fit_transform(data_cleaned)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ngram_df = pd.DataFrame(ngram_features.toarray(), columns=vectorizer_ngram.get_feature_names_out())\n",
    "print(ngram_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [(terrible, JJ), (experience, NN), (hate, NN)]\n",
      "1              [(love, VB), (product, NN), (amaze, NN)]\n",
      "2                            [(happy, JJ), (order, NN)]\n",
      "3     [(worst, JJS), (service, NN), (ever, RB), (rec...\n",
      "4     [(worst, JJS), (service, NN), (ever, RB), (rec...\n",
      "                            ...                        \n",
      "95    [(absolutely, RB), (fantastic, JJ), (great, JJ...\n",
      "96    [(poor, JJ), (quality, NN), (break, NN), (week...\n",
      "97    [(best, JJS), (purchase, NN), (ive, JJ), (make...\n",
      "98                           [(happy, JJ), (order, NN)]\n",
      "99    [(best, JJS), (purchase, NN), (ive, JJ), (make...\n",
      "Name: cleaned_text, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# part of speech\n",
    "def get_pos_tags(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "data_pos = data_cleaned.apply(get_pos_tags)\n",
    "print(data_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['label']\n",
    "\n",
    "# Split data into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.53      0.62        15\n",
      "           1       0.22      0.40      0.29         5\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.47      0.47      0.45        20\n",
      "weighted avg       0.60      0.50      0.53        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p=tfidf.transform(['terrible experience hate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.predict(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
