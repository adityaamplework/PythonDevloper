{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"llama3-8b-8192\"\n",
    "llm=ChatGroq(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store={}\n",
    "# def memory_history(session_id,user_input,summerize=False):\n",
    "#     if session_id not in store:\n",
    "#         store[session_id] = []  \n",
    "#     if summerize:\n",
    "#         store[session_id]=[f\"Summary: {user_input}\"]\n",
    "            \n",
    "#     else:\n",
    "#         store[session_id].append(user_input)\n",
    "\n",
    "#     return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bot(session_id):\n",
    "#     count=0\n",
    "#     while True:\n",
    "#         query=input(\"Search Your question\")\n",
    "        \n",
    "#         if query.lower()==\"quit\":\n",
    "#             print(\"Exiting the chatbot. Have a great day!\")\n",
    "#             break    \n",
    "        \n",
    "        \n",
    "#         chat_history = \"\\n\".join(store.get(session_id, [])) \n",
    "#         if count>0:\n",
    "#             summerize=llm.invoke(f\"Write a concise summary of the following:\\n{chat_history}\") \n",
    "        \n",
    "#             full_input = f\"Chat History:\\n{summerize}\\nUser: {query}\"\n",
    "#             memory_history(session_id, summerize,summerize=True)\n",
    "            \n",
    "#         else:\n",
    "#             full_input=query\n",
    "#             count+=1    \n",
    "            \n",
    "            \n",
    "       \n",
    "#         result=llm.invoke(full_input)\n",
    "        \n",
    "             \n",
    "#         memory_history(session_id, f\"User: {query}\")\n",
    "#         memory_history(session_id, f\"Bot: {result}\")\n",
    "           \n",
    "        \n",
    "#         print('............................................................................................................')\n",
    "#         print(\"User:\",query)\n",
    "#         print(\"Bot:\",result.content)\n",
    "#         print('............................................................................................................')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot('chat1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summerization Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "memory1 = ConversationSummaryMemory(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot1():\n",
    "    \n",
    "    while True:\n",
    "        query=input(\"Search Your question\")\n",
    "        \n",
    "        if query.lower()==\"quit\":\n",
    "            print(\"Exiting the chatbot. Have a great day!\")\n",
    "            break  \n",
    "        memory1.save_context({\"input\": query}, {\"output\": \"\"})\n",
    "        prompt=f\"Use the context for questions answering questions is :{query} and context is: {memory1.load_memory_variables({})['history']}\"\n",
    "        result=llm.invoke(prompt)\n",
    "        \n",
    "        memory1.save_context({\"input\": query}, {\"output\": result.content})\n",
    "        \n",
    "        print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to provide a new set of lines of conversation that are grammatically correct and make sense. Here is a new context:\n",
      "\n",
      "**New Context:**\n",
      "\n",
      "User: Can you summarize the main points of the article about the new AI technology?\n",
      "Assistant: I'd be happy to help. What article are you referring to?\n",
      "\n",
      "Please feel free to respond with the next line of conversation, and I'll be happy to assist you with summarizing it progressively.\n",
      "I'd be happy to help summarize an article about new AI technology. However, I want to clarify that the initial input \"785665222222222*8566\" seems to be a random sequence of numbers and doesn't appear to be a coherent statement. Could you please provide a more meaningful or clear starting point for our conversation?\n",
      "Exiting the chatbot. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "bot1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ConversationSummaryBufferMemory\nllm\n  Input should be a valid dictionary or instance of BaseLanguageModel [type=model_type, input_value=RunnableBinding(bound=Cha...{}, config_factories=[]), input_type=RunnableBinding]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationSummaryBufferMemory\n\u001b[1;32m----> 2\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationSummaryBufferMemory(llm\u001b[38;5;241m=\u001b[39mmodel_with_tools)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ConversationSummaryBufferMemory\nllm\n  Input should be a valid dictionary or instance of BaseLanguageModel [type=model_type, input_value=RunnableBinding(bound=Cha...{}, config_factories=[]), input_type=RunnableBinding]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot():\n",
    "    \n",
    "    while True:\n",
    "        query=input(\"Search Your question\")\n",
    "        \n",
    "        if query.lower()==\"quit\":\n",
    "            print(\"Exiting the chatbot. Have a great day!\")\n",
    "            break  \n",
    "        memory.save_context({\"input\": query}, {\"output\": \"\"})\n",
    "        prompt=f\"Use the context for questions answering questions is :{query} and context is: {memory.load_memory_variables({})['history']}\"\n",
    "        result=llm.invoke(prompt)\n",
    "        \n",
    "        memory.save_context({\"input\": query}, {\"output\": result.content})\n",
    "        \n",
    "        print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human, Aditya, has provided a mathematical expression: 785665222222222*8566.\n",
      "\n",
      "AI: Ah, it looks like Aditya has given us a math problem! Let me calculate the result...\n",
      "\n",
      "After performing the multiplication, I get:\n",
      "\n",
      "6,743,888,999,999,996\n",
      "\n",
      "AI: And the answer is... 6,743,888,999,999,996!\n",
      "Since the human, Aditya, has already provided the mathematical expression 785665222222222*8566, I'll respond accordingly.\n",
      "\n",
      "AI: Ah, we've already calculated the result earlier! The answer is 6,743,888,999,999,996. Would you like to try another math problem, Aditya?\n",
      "Exiting the chatbot. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "bot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calling using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"\n",
    "    Multiplies two integers.\n",
    "    \n",
    "    Parameters:\n",
    "    a (int): The first number.\n",
    "    b (int): The second number.\n",
    "    \n",
    "    Returns:\n",
    "    int: The result of multiplying the two integers.\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "output=multiply.args\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
