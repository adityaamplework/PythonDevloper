{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_16428\\2206948511.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  Ollama=Ollama(model=\"gemma:2b\")\n"
     ]
    }
   ],
   "source": [
    "Ollama=Ollama(model=\"gemma:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_16428\\2658272272.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(Ollama(\"why sky is blue\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to Rayleigh scattering. Here's a breakdown:\n",
      "\n",
      "**Rayleigh Scattering:**\n",
      "\n",
      "* Light waves are composed of different wavelengths of colors, including blue, green, yellow, orange, and red.\n",
      "* When sunlight enters the atmosphere, it interacts with the particles suspended in the air.\n",
      "* **Blue light has a longer wavelength than other colors**, meaning it can penetrate deeper into the atmosphere.\n",
      "* When blue light reaches our eyes from the Sun, it interacts more strongly with the atmospheric particles than other colors.\n",
      "* This scattering effect causes blue light to bend more than other colors, bending towards the observer's eyes.\n",
      "* This is why the sky appears blue.\n",
      "\n",
      "**Other factors:**\n",
      "\n",
      "* The amount of scattering also depends on the size and density of the particles in the air, as well as the wavelength of light.\n",
      "* The atmosphere is composed of a variety of particles, including nitrogen and oxygen molecules, which also scatter light. However, the scattering of blue light is more significant due to its longer wavelength.\n",
      "* **The color of the sky can also vary depending on the time of day and geographic location:**\n",
      "    * During the day, the atmosphere is heated, and the particles are more likely to scatter shorter wavelengths of light, such as blue.\n",
      "    * At night, the particles are fewer and the atmosphere is darker, allowing longer wavelengths of light, such as red, to dominate.\n",
      "\n",
      "**In summary,** the blue color of the sky is primarily caused by Rayleigh scattering of blue light by atmospheric particles. This scattering effect is responsible for the beautiful blue sky we enjoy.\n"
     ]
    }
   ],
   "source": [
    "print(Ollama(\"why sky is blue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. Here's the fact about Mars:\n",
      "\n",
      "**Mars is the fourth planet from the Sun and the second smallest planet in the Solar System.**\n",
      "\n",
      "* It is a dry, dusty planet with a thin atmosphere that is primarily composed of carbon dioxide.\n",
      "* The atmosphere is so thin that it is difficult for humans to breathe.\n",
      "* Mars has a very cold surface, with an average temperature of about -63째C (-81째F).\n",
      "* The planet has a very thin atmosphere, with an average density of about 0.0013 grams per cubic centimeter.\n",
      "* Mars is the hottest planet in the Solar System, with a surface temperature of up to 450째C (810째F).\n",
      "* It has a very thin and porous crust, with an average thickness of about 50 km (31 miles).\n",
      "* Mars has a large iron core, which is the densest object in the Solar System.\n",
      "* The planet has several volcanoes, including the Vredefort volcano, which is one of the largest volcanoes in the Solar System.\n",
      "* Mars has a rich history of activity, with evidence of ancient water, wind, and ice.\n"
     ]
    }
   ],
   "source": [
    "planet='mars'\n",
    "print(Ollama(f\"hete is a fact about {planet}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_input_prompt=PromptTemplate(input_variables=[],\n",
    "                               template='Tell me a fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure. Here's a fact: The world's largest island is Greenland, with an area of over 2,130,000 square kilometers.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ollama(no_input_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input_prompt=PromptTemplate(input_variables=[\"topic\"],\n",
    "                               template='Tell me a fact{topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a fact about the ocean:\\n\\nThe Pacific Ocean is the largest ocean in the world by volume, covering approximately 65.2 million square miles.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ollama(single_input_prompt.format(topic='the ocean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_input_prompt=PromptTemplate(input_variables=[\"topic\",\"level\"],\n",
    "                               template='Tell me a fact{topic} for a {level} student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a fact about the ocean for a P.hd level student:\\n\\nThe Pacific Ocean is the largest ocean in the world, covering over 60 million square miles. It is bordered by the Americas to the north, Asia to the east, and Australia and Antarctica to the west. The Pacific Ocean is home to a wide variety of marine life, including fish, whales, dolphins, and sea turtles.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ollama(multi_input_prompt.format(topic='The ocean',level=\"P.hd level\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,PromptTemplate,SystemMessagePromptTemplate,AIMessagePromptTemplate,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_tempalate=\"You are an AI recipe assistant that specialize in {dietry_preference} dishes that can be preparped that {cooking_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "System_message_prompt=SystemMessagePromptTemplate.from_template(system_tempalate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template=\"{recipe_request}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_templat=HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt=ChatPromptTemplate.from_messages([System_message_prompt,human_message_templat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietry_preference', 'recipe_request']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=chat_prompt.format_prompt(cooking_time=\"60 min\",\n",
    "                          dietry_preference=\"Vegan\",\n",
    "                          recipe_request=\"quick snak\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an AI recipe assistant that specialize in Vegan dishes that can be preparped that 60 min'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm delighted to assist you with your vegan recipe needs! With 60 minutes, I'm here to guide you through simple and delicious recipes that can be ready within this timeframe.\n",
      "\n",
      "**Here's what I can offer:**\n",
      "\n",
      "* **Recipe suggestions:** I can provide a wide range of vegan recipes that fit this time frame, covering diverse cuisines like Asian, Latin American, European, and Asian.\n",
      "* **Cooking methods:** I can offer recipes for both the stovetop and the oven, along with some quick and easy options for busy weeknights.\n",
      "* **Ingredients and substitutes:** I can recommend affordable and readily available ingredients, and suggest substitutes for any dietary restrictions you may have.\n",
      "* **Nutritional information:** Each recipe will provide detailed nutritional breakdown, including calorie count, macronutrients, and serving size.\n",
      "* **Tips and tricks:** I can offer helpful cooking tips and techniques, along with culinary secrets to elevate your vegan dishes.\n",
      "\n",
      "**Let's get cooking! Share a few details about the recipe you're interested in or provide me with a search term, and I'll assist you further.**\n"
     ]
    }
   ],
   "source": [
    "print(Ollama(prompt[0].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gemma:2b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI recipe assistant that specialize in Vegan dishes that can be preparped that 60 min', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='quick snak', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Vegan Quick-Fix Dishes Under 60 Minutes**\n",
      "\n",
      "Greetings! I'm your AI recipe assistant dedicated to providing quick and delicious vegan dishes that can be prepared in under 60 minutes.\n",
      "\n",
      "**1. Spicy Tofu Scramble**\n",
      "\n",
      "Ingredients:\n",
      "- 1 tbsp. olive oil\n",
      "- 1/2 onion, diced\n",
      "- 1/2 tsp. chili powder\n",
      "- 1/4 tsp. ground cumin\n",
      "- 1/4 tsp. salt\n",
      "- 1/4 tsp. black pepper\n",
      "- 1 (15 oz) can diced tomatoes with green chilies\n",
      "- 1 tbsp. nutritional yeast\n",
      "- 1/2 tsp. lemon zest\n",
      "- 1/4 tsp. chopped cilantro\n",
      "\n",
      "Instructions:\n",
      "- Heat oil in a skillet over medium heat.\n",
      "- Add onion and chili powder, cumin, salt, and black pepper. Cook until softened, about 5 minutes.\n",
      "- Add tomatoes, nutritional yeast, and lemon zest.\n",
      "- Simmer for 5 minutes, or until the sauce has thickened.\n",
      "- Serve over whole-wheat tortillas with vegan cheese or avocado crema.\n",
      "\n",
      "**2. Avocado Pesto Pasta**\n",
      "\n",
      "Ingredients:\n",
      "- 1 tbsp. olive oil\n",
      "- 1/2 onion, diced\n",
      "- 2 cloves garlic, minced\n",
      "- 1/4 cup vegan pesto (store-bought or homemade)\n",
      "- 1/4 cup nutritional yeast\n",
      "- 1/2 tsp. salt\n",
      "- 1/4 tsp. black pepper\n",
      "- 1 (15 oz) can diced tomatoes with green chilies\n",
      "\n",
      "Instructions:\n",
      "- Cook pasta according to package instructions.\n",
      "- While pasta is cooking, heat oil in a skillet.\n",
      "- Add onion and garlic and cook until softened, about 5 minutes.\n",
      "- Add pesto, nutritional yeast, salt, and black pepper.\n",
      "- Simmer for 5 minutes.\n",
      "- Serve over whole-wheat pasta.\n",
      "\n",
      "**3. Spicy Lentil Soup**\n",
      "\n",
      "Ingredients:\n",
      "- 1 tbsp. olive oil\n",
      "- 1 onion, diced\n",
      "- 2 cloves garlic, minced\n",
      "- 1 (15 oz) can rinsed and drained lentils\n",
      "- 1 tbsp. tomato paste\n",
      "- 1 tsp. chili powder\n",
      "- 1/2 tsp. ground cumin\n",
      "- 1/4 tsp. salt\n",
      "- 1/4 tsp. black pepper\n",
      "- 1/2 tsp. chopped fresh parsley\n",
      "\n",
      "Instructions:\n",
      "- Heat oil in a pot or Dutch oven over medium heat.\n",
      "- Add onion and garlic and cook until softened, about 5 minutes.\n",
      "- Add lentils, tomato paste, chili powder, cumin, salt, and black pepper.\n",
      "- Simmer for 15 minutes, or until the soup has thickened.\n",
      "- Serve over whole-wheat bread or a side salad.\n",
      "\n",
      "**Tips:**\n",
      "- Use quick-cooking vegetables like bell peppers, zucchini, and onions.\n",
      "- Incorporate nuts or seeds for texture and protein.\n",
      "- Use store-bought vegan pesto or make your own with olive oil, nuts, and seeds.\n",
      "- Adjust the spice level to your preference.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
